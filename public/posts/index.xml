<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog posts on TuesdayBornWhale</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Blog posts on TuesdayBornWhale</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Sep 2025 20:32:28 +0200</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Two red-team critiques of METR&#39;s research on long tasks</title>
      <link>http://localhost:1313/posts/metr_long_tasks/</link>
      <pubDate>Tue, 16 Sep 2025 20:32:28 +0200</pubDate>
      <guid>http://localhost:1313/posts/metr_long_tasks/</guid>
      <description>&lt;p&gt;AI benchmarks are one attempt to track and formalise the progress of AI&amp;rsquo;s developing capabilities. As explained succinctly in the introduction to &lt;a href=&#34;https://arxiv.org/abs/2503.14499&#34;&gt;&amp;ldquo;Measuring AI Ability to Complete Long Tasks&amp;rdquo;&lt;/a&gt; (Kwa et al.), published by METR this year, commonly used benchmarks suffer from a variety of issues. One of them is that it&amp;rsquo;s hard to track AI progress across time because benchmarks are often not mutually comparable. METR proposes a metric which addresses this problem: the X% (task completion) time horizon, defined as the maximum length of task for a human that an AI can complete X% of the time. I really like this metric as an attempt to quantitatively come to grips with how AI is developing over time.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Can superhuman AI help us improve?</title>
      <link>http://localhost:1313/posts/learning_from_superhumanai/</link>
      <pubDate>Sat, 13 Sep 2025 22:47:46 +0200</pubDate>
      <guid>http://localhost:1313/posts/learning_from_superhumanai/</guid>
      <description>&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;script&gt;&#xD;&#xA;  MathJax = {&#xD;&#xA;    tex: {&#xD;&#xA;      displayMath: [[&#39;\\[&#39;, &#39;\\]&#39;], [&#39;$$&#39;, &#39;$$&#39;]],  &#xD;&#xA;      inlineMath: [[&#39;\\(&#39;, &#39;\\)&#39;], [&#39;$&#39;, &#39;$&#39;]]      &#xD;&#xA;    },&#xD;&#xA;    loader:{&#xD;&#xA;      load: [&#39;ui/safe&#39;]&#xD;&#xA;    },&#xD;&#xA;  };&#xD;&#xA;&lt;/script&gt;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&lt;figure&gt;&#xD;&#xA;  &#xD;&#xA;  &lt;img src=&#34;http://localhost:1313/images/human_AI_gap.png&#34; alt=&#34;&#34; title=&#34;&#34;&gt;&#xD;&#xA;  &#xD;&#xA;&#xD;&#xA;  &#xD;&#xA;    &lt;figcaption&gt;&#xD;&#xA;      &#xD;&#xA;        &lt;div class=&#34;figure-caption&#34;&gt;Graph showing drop in the gap between human experts and AI in Go since AI. From &lt;a href=&#34;https://arxiv.org/pdf/2012.15035&#34;&gt;Shin et. al (2020)&lt;/a&gt;&lt;/div&gt;&#xD;&#xA;      &#xD;&#xA;    &lt;/figcaption&gt;&#xD;&#xA;  &#xD;&#xA;&lt;/figure&gt;&#xD;&#xA;&#xA;&lt;p&gt;As AI continues to improve at writing and math-based tasks, it seems plausible that it either has or soon will surpass domain experts in these tasks. This post aims to explore to what extent  superhuman AI in a domain can instruct and empower humans to improve for themselves.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Making Mathematical MONSTERS</title>
      <link>http://localhost:1313/posts/math_monsters/</link>
      <pubDate>Fri, 08 Aug 2025 16:54:54 +0200</pubDate>
      <guid>http://localhost:1313/posts/math_monsters/</guid>
      <description>&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;script&gt;&#xD;&#xA;  MathJax = {&#xD;&#xA;    tex: {&#xD;&#xA;      displayMath: [[&#39;\\[&#39;, &#39;\\]&#39;], [&#39;$$&#39;, &#39;$$&#39;]],  &#xD;&#xA;      inlineMath: [[&#39;\\(&#39;, &#39;\\)&#39;], [&#39;$&#39;, &#39;$&#39;]]      &#xD;&#xA;    },&#xD;&#xA;    loader:{&#xD;&#xA;      load: [&#39;ui/safe&#39;]&#xD;&#xA;    },&#xD;&#xA;  };&#xD;&#xA;&lt;/script&gt;&#xA;&lt;h3 id=&#34;introduction-axiomatizing-natural-numbers&#34;&gt;Introduction: axiomatizing natural numbers&lt;/h3&gt;&#xA;&lt;p&gt;In math, we often define objects whose existence and properties seem obvious and common place. For example, many introductory university level courses will go out of their way to define the natural numbers. As mundane as this process can seem, I like the mental motion of formalizing such obvious objects. I see at as a sampling of our sub-conscious: a brief taste of the contents of our minds that rarely, if ever, exit the world of the murky and implicit.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Axiomatic jigsaw puzzles: probability</title>
      <link>http://localhost:1313/posts/axiom_jigsaws/</link>
      <pubDate>Sat, 23 Dec 2023 20:58:03 +0200</pubDate>
      <guid>http://localhost:1313/posts/axiom_jigsaws/</guid>
      <description>&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;script&gt;&#xD;&#xA;  MathJax = {&#xD;&#xA;    tex: {&#xD;&#xA;      displayMath: [[&#39;\\[&#39;, &#39;\\]&#39;], [&#39;$$&#39;, &#39;$$&#39;]],  &#xD;&#xA;      inlineMath: [[&#39;\\(&#39;, &#39;\\)&#39;], [&#39;$&#39;, &#39;$&#39;]]      &#xD;&#xA;    },&#xD;&#xA;    loader:{&#xD;&#xA;      load: [&#39;ui/safe&#39;]&#xD;&#xA;    },&#xD;&#xA;  };&#xD;&#xA;&lt;/script&gt;&#xA;&lt;p&gt;&lt;em&gt;&amp;lsquo;Anytime someone finds a problem with your axioms, you just say &amp;ldquo;oh, but of course that&amp;rsquo;s not what I meant,&amp;rdquo; and you change the axioms.&amp;rsquo;&lt;/em&gt; - cool math prof&lt;/p&gt;&#xA;&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;&#xA;&lt;p&gt;I recently came across the &lt;a href=&#34;https://archive.org/details/kolmogorov_202112&#34;&gt;&amp;lsquo;Foundations of the Theory of Probability,&amp;rsquo;&lt;/a&gt; a 1933 paper by A.N. Kolmogorov which outlines the &amp;lsquo;canonical&amp;rsquo; formalization of probability theory which we know and love(?) today. I took a probability course last semester and expected the content of Kolmogorov&amp;rsquo;s paper to be very similar to what I had learned. It was therefore surprising and delightful to find that the foundational axioms given by Kolmogorov are substantially different from the ones I am used to.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
